title:: Bytes: Benchmarketing 101 by Tyler from ui.dev
author:: [[Tyler from ui.dev]]
full-title:: "Bytes: Benchmarketing 101"
category:: #articles
url:: https://feedly.com/i/entry/CvtUlZS8TKNGPcZ/CRM/EdfAAYlcOeB5GZ3SQyg6e9I=_184e310d29b:897e0b:e6d9166a

- [[Highlights]] first synced by [[Readwise]] [[December 5th, 2022]]
	- Todayâ€™s issue:
	  
	  Impolite data structures
	  Lukewarm Mr. Pibb
	  The crypto trade of a lifetime
	  
	  Welcome to #142 - you can read it online here.
	  
	  
	  The Main Thing
	  
	  
	  When the hot new OSS tool is not quite as blazing as it claimed 
	  
	  Benchmarketing 101
	  FOMO is a hell of a drug. Thatâ€™s why, no matter how rational we *think* we are, our lizard brains simply canâ€™t resist a â€œ10x lightning fastâ€ benchmark for a new OSS tool.
	  OSS creators know this, which is why some of them spend a lot of time crafting benchmarks that always show their tool as being #1 Most Blazingest. And while itâ€™s natural to want to highlight the strengths of your own project, sometimes this benchmarketing (ğŸ¥) can cause some real confusion.
	  Vercel recently came under fire for their Turbopack-vs-Vite benchmarks, Bun was questioned (but then mostly defended for their SSR benchmarks, and the list goes on. So, as concerned citizens of JavaScript-land, we wanted to share a few benchmarking practices to look out for when evaluating various OSS claims.
	  Letâ€™s start with a few red flags ğŸš©:
	  
	  
	  Not public: If you canâ€™t run a benchmark yourself, you should probably be skeptical.
	  
	  
	  Lacks context: Does the benchmark include context about what their assumptions are? Measuring performance on â€œhello worldâ€ can be wildly different than a huge application.
	  
	  
	  Unclear methodology: Things like what machine the benchmarks are run on, how many times they ran, and what use cases are covered, all matter. If those things are unclear, your spidey senses should be going off.
	  
	  
	  Here are a few best practices we love to see ğŸ¤©:
	  
	  
	  Everyone agrees on what to measure: Standardized benchmarks ftw. Codefied standards are more common for larger and more established projects like browsers â€” but the more we can all agree on, the better.
	  
	  
	  You benchmark against yourself: This is the best way to give comparisons that are truly ğŸâ€™s to ğŸâ€™s, and thereâ€™s a lot to be said for transparently running your own race.
	  
	  
	  Bottom Line: In a perfect world, weâ€™d have some sort of third-party benchmark for benchmarking the quality of every benchmark. But since that job sounds like actual hell, weâ€™ll probably just have to keep trying to decipher the data ourselves â€” and celebrate the times when great benchmarking helps us all win.
	  Â Â Â Â Â Â 
	  
	  
	  
	  Our Friends (With Benefits)
	  
	  
	  Can't wait to hand-roll those back-end APIs 
	  
	  
	  Directus can help you
	  You know whatâ€™s cool? Building things your users love. You know what isnâ€™t cool? Building backen